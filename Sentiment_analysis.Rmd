---
title: "Sentiment_analysis"
output: html_document
date: "2025-05-31"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(syuzhet)
library(dplyr)
library(readr)
library(tidytext)
library(tidyverse)
library(textclean)
library(topicmodels)
library(devtools)
library(tokenizers)
library(stringr)
library(tibble)
library(ggplot2)
library(keras)
library(yardstick)
library(text2vec)
library(cluster)
library(factoextra)
library(igraph)
library(ggraph)
library(tidygraph)
library(tidyverse)
library(wordcloud)


#install.packages(c("tm", "BMS", "quadprog", "rJava", "parallel", "data.table", "entropy"))
#library(rJava)
#.jinit()
#remotes::install_github("blogsvoices/iSAX")
```


```{r cars, include=FALSE}
data1<-read_csv("/Users/melaniauccello/Desktop/Network science e text mining/Esame_TextMining/nutrition_comments_cleaned.csv")
View(data1)

data2<-read_csv("/Users/melaniauccello/Desktop/Network science e text mining/Esame_TextMining/nutrition_threads_cleaned.csv")
View(data2)
```
### Analisi dei set di dati come unico documento per capire il sentimento predominante
```{r, echo=FALSE}
data1$Cleaned_Comment <- gsub("[^[:alnum:] ]", "", data1$Cleaned_Comment)
data2$Cleaned_Text <- gsub("[^[:alnum:] ]", "", data2$Cleaned_Text)

# Unisci tutti i testi della colonna 'Cleaned_Comment' in un singolo testo (per data1)
text1 <- paste(data1$Cleaned_Comment, collapse = " ")

# Unisci tutti i testi della colonna 'Cleaned_Text' in un singolo testo (per data2)
text2 <- paste(data2$Cleaned_Text, collapse = " ")

```

```{r}
# Analisi del sentiment per il testo del data1
sentiment1 <- get_nrc_sentiment(text1)

# Analisi del sentiment per il testo del data2
sentiment2 <- get_nrc_sentiment(text2)

# Visualizza i risultati
print(colSums(sentiment1))
print(colSums(sentiment2))

```


```{r}
sentiment_pred1<-which.max(colSums(sentiment1))  # Sentimento dominante data1
sentiment_pred2<-which.max(colSums(sentiment2))# Sentimento dominante data2

print(sentiment_pred1)
print(sentiment_pred2)
```


```{r}
# Prepara comments
comments <- data1 %>%
  select(text = Cleaned_Comment) %>%
  mutate(source = "comments")

# Prepara threads
threads <- data2 %>%
  select(text = Cleaned_Text) %>%
  mutate(source = "threads")

# Carica NRC (solo emozioni)
nrc_emotions <- get_sentiments("nrc") %>%
  filter(!sentiment %in% c("positive", "negative"))

# Tokenizzazione + conteggio per comments
emotion_comments <- comments %>%
  unnest_tokens(word, text) %>%
  inner_join(nrc_emotions, by = "word") %>%
  count(sentiment, sort = TRUE) %>%
  mutate(percent = n / sum(n) * 100,
         source = "comments")

# Tokenizzazione + conteggio per threads
emotion_threads <- threads %>%
  unnest_tokens(word, text) %>%
  inner_join(nrc_emotions, by = "word") %>%
  count(sentiment, sort = TRUE) %>%
  mutate(percent = n / sum(n) * 100,
         source = "threads")


ggplot(emotion_comments, aes(x = reorder(sentiment, -percent), y = percent)) +
  geom_bar(stat = "identity", fill = "#66c2a5") +
  labs(title = "Distribuzione Emozioni nei Commenti", x = "Emozione", y = "Frequenza (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


ggplot(emotion_threads, aes(x = reorder(sentiment, -percent), y = percent)) +
  geom_bar(stat = "identity", fill = "#fc8d62") +
  labs(title = "Distribuzione Emozioni nei Thread", x = "Emozione", y = "Frequenza (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
# Unione dei due dataset
emotion_comparison <- bind_rows(emotion_comments, emotion_threads)
ggplot(emotion_comparison, aes(x = sentiment, y = percent, fill = source)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Confronto delle Emozioni tra Commenti e Thread",
    x = "Emozione",
    y = "Frequenza (%)",
    fill = "Fonte"
  ) +
  scale_fill_manual(values = c("comments" = "#66c2a5", "threads" = "#fc8d62")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### Valutazione del sentimento di ciascuna frase nei due set di dati (separatamente) al fine di individuare le opinioni contrastanti

```{r}
# Calcola il sentiment per ciascun commento
sentiment_data1 <- get_nrc_sentiment(data1$Cleaned_Comment)

# Combina i risultati con i dati originali
data1_sentiment <- bind_cols(data1, sentiment_data1)

# Visualizza le prime righe
head(data1_sentiment)

```

```{r}
# Calcola il sentiment per ciascun commento
sentiment_data2 <- get_nrc_sentiment(data2$Cleaned_Text)

# Combina i risultati con i dati originali
data2_sentiment <- bind_cols(data2, sentiment_data2)

# Visualizza le prime righe
head(data2_sentiment)

```

```{r}
# Funzione per determinare contrasto
check_contrast <- function(df) {
  df %>%
    mutate(
      positive = positive,
      negative = negative,
      contrast = ifelse(positive > 0 & negative > 0, TRUE, FALSE)
    )
}

# Applica la funzione
data1_sentiment <- check_contrast(data1_sentiment)
data2_sentiment <- check_contrast(data2_sentiment)

# Filtra solo i commenti contrastanti
contrasting_comments1 <- filter(data1_sentiment, contrast == TRUE)
contrasting_comments2 <- filter(data2_sentiment, contrast == TRUE)

# Visualizza
#contrasting_comments1$Cleaned_Comment
#contrasting_comments2$Cleaned_Text

head(contrasting_comments1$Cleaned_Comment, 10)
head(contrasting_comments2$Cleaned_Text, 10)
```
WORDCLOUD DELLE PAROLE MAGGIORMENTE EMOTIVE
```{r}
wordcloud(
  words = data1_sentiment$Cleaned_Comment,
  min.freq = 150,
  random.order = FALSE,
  colors = brewer.pal(8, "Dark2"),  # Puoi cambiare la palette (es: "Set1", "Pastel1")
  scale = c(4, 0.5),                # Dimensione massima e minima delle parole
  rot.per = 0.25                    # Percentuale di parole ruotate (verticali)
)
```

```{r}
wordcloud(
  words = data2_sentiment$Cleaned_Text,
  min.freq = 500,
  random.order = FALSE,
  colors = brewer.pal(8, "Dark2"),  # Puoi cambiare la palette (es: "Set1", "Pastel1")
  scale = c(4, 0.5),                # Dimensione massima e minima delle parole
  rot.per = 0.25                    # Percentuale di parole ruotate (verticali)
)
#wordcloud(words = data2_sentiment$Cleaned_Text, min.freq = 500)
```



### ABSA

In sentiment analysis, polarità indica la direzione emotiva espressa in un testo:
Positive, Neutral, Negative.
Abbiamo definito un dizionario manuale con parole chiave.
Ogni commento/testo è stato diviso in frasi per analizzare in modo più preciso le emozioni per ciascun aspetto.
Abbiamo selezionato solo le frasi contenenti almeno uno degli aspetti del dizionario.
Abbiamo usato syuzhet::get_sentiment() per assegnare un punteggio numerico di sentiment a ciascuna frase. Poi lo abbiamo trasformato in polarità (positive, negative, neutral).

```{r}
# Dizionario manuale di aspetti rilevanti per nutrizione
aspect_terms <- c("appointment", "goal", "rapport", "session", "diet", "supplement", "follow-up", "plan", "history")

# Tokenizza i commenti in frasi
data1_sentences <- data1 %>%
  mutate(sentences = tokenize_sentences(Cleaned_Comment)) %>%
  unnest(sentences) %>%
  rename(sentence = sentences)

# Filtra solo le frasi che contengono almeno un aspetto
aspect_pattern <- str_c("\\b(", str_c(aspect_terms, collapse = "|"), ")\\b")
data1_aspects <- data1_sentences %>%
  filter(str_detect(sentence, regex(aspect_pattern, ignore_case = TRUE)))

# Calcola il sentiment della frase
data1_aspects <- data1_aspects %>%
  mutate(sentiment_score = get_sentiment(sentence, method = "syuzhet"),
         polarity = case_when(
           sentiment_score > 0 ~ "positive",
           sentiment_score < 0 ~ "negative",
           TRUE ~ "neutral"
         ))

View(data1_aspects)
```

```{r}
data1_aspects %>%
  count(polarity, sort = TRUE)

data1_aspects %>%
  group_by(polarity) %>%
  summarise(avg_sentiment = mean(sentiment_score))

```

```{r}
# Dizionario manuale di aspetti rilevanti per nutrizione
# Includi aspetti multi-parola
aspect_terms <- c(
  "appointment", "goal", "rapport", "session", "diet", "supplement",
  "follow-up", "plan", "history", "retention", "counselling", "assessment",
  "meal plan",          # Esempio di aspetto multi-parola
  "eating habits",      # Esempio di aspetto multi-parola
  "nutrition plan",     # Esempio di aspetto multi-parola
  "healthy eating",     # Esempio di aspetto multi-parola
  "weight loss",        # Esempio di aspetto multi-parola
  "food choices",       # Esempio di aspetto multi-parola
  "dietary changes"     # Esempio di aspetto multi-parola
)

# Per creare il pattern, assicurati che le frasi più lunghe vengano controllate per prime
# Questo evita che "plan" venga trovato prima di "nutrition plan"
aspect_terms_ordered <- aspect_terms[order(-nchar(aspect_terms))]

# Crea il pattern regex per la ricerca degli aspetti, ignorando le maiuscole/minuscole.
# Usiamo str_c(..., collapse = "|") per unire i termini con un OR.
# L'uso di "\\b" (boundary) è più adatto per singole parole.
# Per frasi, potremmo voler essere più flessibili o usare una logica diversa.
# Un approccio comune è usare la funzione 'str_detect' con 'regex' e 'ignore_case'.
# Per includere multi-parole, potremmo semplicemente elencarle, e l'ordine aiuta.
aspect_pattern <- str_c("(", str_c(aspect_terms_ordered, collapse = "|"), ")")

# Modifica le tue sezioni data1_aspects e data2_aspects come segue:

# Filtra solo le frasi che contengono almeno un aspetto
data1_aspects <- data1_sentences %>%
  filter(str_detect(sentence, regex(aspect_pattern, ignore_case = TRUE))) %>%
  mutate(matched_aspect = str_extract(sentence, regex(aspect_pattern, ignore_case = TRUE)))

# Calcola il sentiment della frase
data1_aspects <- data1_aspects %>%
  mutate(sentiment_score = get_sentiment(sentence, method = "syuzhet"),
         polarity = case_when(
           sentiment_score > 0 ~ "positive",
           sentiment_score < 0 ~ "negative",
           TRUE ~ "neutral"
         ))

View(data1_aspects)
```


```{r}
# Ripeti lo stesso per data2_aspects:
data2_sentences <- data2 %>%
  mutate(sentences = tokenize_sentences(Cleaned_Text)) %>%
  unnest(sentences) %>%
  rename(sentence = sentences)

data2_aspects <- data2_sentences %>%
  filter(str_detect(sentence, regex(aspect_pattern, ignore_case = TRUE)))

data2_aspects <- data2_aspects %>%
  mutate(sentiment_score = get_sentiment(sentence, method = "syuzhet"),
         polarity = case_when(
           sentiment_score > 0 ~ "positive",
           sentiment_score < 0 ~ "negative",
           TRUE ~ "neutral"
         ))
```

```{r}
data2_aspects %>%
  count(polarity, sort = TRUE)

data2_aspects %>%
  group_by(polarity) %>%
  summarise(avg_sentiment = mean(sentiment_score))

```

```{r}
# Filtra solo le frasi che contengono almeno un aspetto
data2_aspects <- data2_sentences %>%
  filter(str_detect(sentence, regex(aspect_pattern, ignore_case = TRUE))) %>%
  mutate(matched_aspect = str_extract(sentence, regex(aspect_pattern, ignore_case = TRUE)))

# Calcola il sentiment della frase
data2_aspects <- data2_aspects %>%
  mutate(sentiment_score = get_sentiment(sentence, method = "syuzhet"),
         polarity = case_when(
           sentiment_score > 0 ~ "positive",
           sentiment_score < 0 ~ "negative",
           TRUE ~ "neutral"
         ))

#View(data2_aspects)
```

```{r}
# Aggiungiamo etichette
data1_aspects <- data1_aspects %>% mutate(source = "comments")
data2_aspects <- data2_aspects %>% mutate(source = "threads")

# Unione
all_aspects <- bind_rows(data1_aspects, data2_aspects)

# Riepilogo con media dei sentimenti
aspect_summary <- all_aspects %>%
  group_by(matched_aspect, polarity) %>%
  summarise(mean_sentiment = mean(sentiment_score), .groups = "drop") %>%
  arrange(desc(abs(mean_sentiment)))


# Visualizzazione con colori pastello
ggplot(aspect_summary, aes(x = reorder(matched_aspect, mean_sentiment), y = mean_sentiment, fill = polarity)) +
  geom_col() +
  coord_flip() +
  labs(title = "Sentiment medio per aspetto", x = "Aspetto", y = "Score medio") +
  scale_fill_manual(values = c(
    "positive" = "#AEDFF7",  # Azzurro pastello
    "negative" = "#D7BDE2",  # Viola chiaro pastello
    "neutral"  = "#FADBD8"   # Rosa salmone pastello
  )) +
  theme_minimal()


```


Differenze di polarità tra commenti e threads

```{r}
# Aggiungiamo etichette
data1_aspects <- data1_aspects %>% mutate(source = "comments")
data2_aspects <- data2_aspects %>% mutate(source = "threads")

# Unione
all_aspects <- bind_rows(data1_aspects, data2_aspects)

ggplot(all_aspects, aes(x = polarity, fill = source)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Confronto Polarità tra Commenti e Thread",
    x = "Polarità del Sentimento",
    y = "Numero di Frasi"
  ) +
  scale_fill_manual(values = c("comments" = "#66c2a5", "threads" = "#fc8d62")) +
  theme_minimal()

```
### Comparative sentiment analysis

Ricostruiamo la gerarchia commenti tramite comment_id
Calcoliamo la polarità (positivo/negativo) per ogni commento
Mettiamo in relazione i commenti con i loro “padri” (commenti cui rispondono)
Valutiamo se sono in accordo o disaccordo emotivo

```{r}
# 1. Aggiungi colonna con ID del commento padre (gerarchia)
get_parent_id <- function(cid) {
  if (!str_detect(cid, "_")) {
    return(NA_character_) # commento root
  } else {
    return(str_remove(cid, "_[^_]+$"))  # rimuove l'ultima parte (più efficiente di str_split)
  }
}

data1 <- data1 %>%
  mutate(parent_comment_id = sapply(comment_id, get_parent_id))

```

```{r}
# 2. Calcolo polarità dei commenti (basato su parole NRC positive/negative)
nrc <- get_sentiments("nrc")

sentiment_comments <- data1 %>%
  select(comment_id, Cleaned_Comment) %>%
  unnest_tokens(word, Cleaned_Comment) %>%
  inner_join(nrc %>% filter(sentiment %in% c("positive", "negative")), by = "word") %>%
  count(comment_id, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(polarity = positive - negative)

```


```{r}
# 3. Abbina commenti figli con i genitori e calcola le polarità
paired_sentiments <- data1 %>%
  select(comment_id, parent_comment_id) %>%
  inner_join(sentiment_comments %>% select(comment_id, polarity), by = "comment_id") %>%
  left_join(sentiment_comments %>% select(comment_id, polarity), 
            by = c("parent_comment_id" = "comment_id"), 
            suffix = c("_child", "_parent")) %>%
  filter(!is.na(polarity_parent))  # esclude i root (che non hanno genitore)

```

```{r}
# 4. Classifica il tipo di accordo/disaccordo emotivo
paired_sentiments <- paired_sentiments %>%
  mutate(agreement = case_when(
    polarity_child * polarity_parent > 0 ~ "accordo",
    polarity_child * polarity_parent < 0 ~ "disaccordo",
    TRUE ~ "neutro"
  ))

# Tabella riepilogativa
table(paired_sentiments$agreement)

```

```{r}
# 5. Visualizzazione
paired_sentiments %>%
  count(agreement) %>%
  mutate(percent = round(n / sum(n) * 100, 1)) %>%
  ggplot(aes(x = agreement, y = percent, fill = agreement)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Accordo/Disaccordo nei commenti figlio-padre",
    x = "Tipo di relazione sentimentale",
    y = "Percentuale (%)"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "accordo" = "#66c2a5", 
    "disaccordo" = "#AEDFF7", 
    "neutro" = "#8da0cb"
  ))

```

heatmap variazione emotiva
```{r}
# 1. Costruisci i nodi con polarità già calcolata
nodes <- sentiment_comments %>%
  mutate(polarity_class = case_when(
    polarity > 0 ~ "positive",
    polarity < 0 ~ "negative",
    TRUE ~ "neutral"
  ))

# 2. Costruisci gli archi (padre → figlio)
edges <- data1 %>%
  select(from = parent_comment_id, to = comment_id) %>%
  filter(!is.na(from))  # escludi root

# 3. Tieni solo gli archi validi (sia padre che figlio esistono nei nodi)
edges_clean <- edges %>%
  filter(from %in% nodes$comment_id & to %in% nodes$comment_id)

# 4. Aggiungi polarità padre e figlio per visualizzazione
edges_clean <- edges_clean %>%
  left_join(nodes %>% select(comment_id, polarity_class), by = c("from" = "comment_id")) %>%
  rename(parent_polarity = polarity_class) %>%
  left_join(nodes %>% select(comment_id, polarity_class), by = c("to" = "comment_id")) %>%
  rename(child_polarity = polarity_class) %>%
  mutate(variation = case_when(
    parent_polarity == child_polarity & !is.na(parent_polarity) ~ "accordo",
    parent_polarity != child_polarity & !is.na(parent_polarity) & !is.na(child_polarity) ~ "disaccordo",
    TRUE ~ "neutro"
  ))

# 5. Costruisci il grafo
graph <- tbl_graph(nodes = nodes, edges = edges_clean, directed = TRUE)

# 6. Visualizzazione
ggraph(graph, layout = "tree") +
  geom_edge_link(aes(color = variation),
                 arrow = arrow(length = unit(2, 'mm')),
                 end_cap = circle(3, 'mm'),
                 alpha = 0.6) +
  geom_node_point(aes(color = polarity_class), size = 3) +
  scale_edge_color_manual(values = c(
    "accordo" = "#66c2a5",     # verde
    "disaccordo" = "#fc8d62",  # rosso
    "neutro" = "gray60"
  )) +
  scale_color_manual(values = c(
    "positive" = "#1b9e77",
    "negative" = "#d95f02",
    "neutral" = "#7570b3"
  )) +
  theme_void() +
  labs(
    title = "Variazione Emotiva nelle Risposte Figlio-Padre",
    color = "Polarità nodo",
    edge_color = "Variazione emotiva"
  )

```

### Sentiment Lexicon Acquisition

Il lexicon è il prodotto finale: un dizionario con parole e punteggi sentimentali.
La lexicon acquisition è il processo per generare quel dizionario, in modo automatico, partendo da dati con annotazioni (ad esempio commenti con score).

Lo script con log-odds ratio usa i commenti etichettati (positivi vs negativi), in seguito calcola quali parole sono più rappresentative di ciascun sentimento
genera così un lexicon personalizzato basato sul tuo dominio (commenti sulla nutrizione)


Si parte da un corpus testuale (es. i tuoi commenti/thread)
Si identifica il sentiment delle parole o espressioni tramite metodi automatici o semi-automatici
Si crea o aggiorna un dizionario parola → polarità/emozione

```{r}
# 2. Definisci la classe di sentiment sulla base del punteggio
data1 <- data1 %>%
  mutate(sentiment_class = case_when(
    score >= 5 ~ "positive",
    score <= 3 ~ "negative",
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(sentiment_class))  # escludi neutri

# 3. Tokenizza i testi
tokens <- data1 %>%
  unnest_tokens(word, Cleaned_Comment) %>%
  filter(!str_detect(word, "\\d")) %>%  # opzionale: rimuovi token numerici
  filter(str_length(word) > 1)          # opzionale: rimuovi parole di 1 carattere

# 4. Conta le occorrenze di ogni parola per classe sentiment
word_counts <- tokens %>%
  count(sentiment_class, word) %>%
  group_by(word) %>%
  filter(sum(n) > 10) %>%  # usa solo parole con frequenza totale > 10
  ungroup()

# 5. Calcola le frequenze totali per classe
total_counts <- word_counts %>%
  group_by(sentiment_class) %>%
  summarise(total = sum(n))

# Conta le occorrenze di ogni parola per classe sentiment
word_counts <- tokens %>%
  count(sentiment_class, word) %>%
  group_by(word) %>%
  filter(sum(n) > 10) %>%  # frequenza minima per parola
  ungroup()

# Calcola totali globali per classe
total_positive <- sum(word_counts$n[word_counts$sentiment_class == "positive"])
total_negative <- sum(word_counts$n[word_counts$sentiment_class == "negative"])

# Riorganizza i dati in wide per parole con conti per classe
word_log_odds <- word_counts %>%
  pivot_wider(names_from = sentiment_class, values_from = n, values_fill = list(n = 0)) %>%
  mutate(
    log_odds = log( (positive + 1) / (total_positive + 1) ) - log( (negative + 1) / (total_negative + 1) )
  ) %>%
  arrange(desc(log_odds))

# Visualizza i risultati
head(word_log_odds)

```
log_odds = misura di associazione: più è alta, più la parola è tipica dei positivi, più è bassa (negativa), più la parola è tipica dei negativi.

```{r}
word_log_odds <- word_log_odds %>%
  mutate(sentiment_label = case_when(
    log_odds > 1 ~ "positive",
    log_odds < -1 ~ "negative",
    TRUE ~ "neutral"
  ))

top_positive <- word_log_odds %>% filter(sentiment_label == "positive") %>% arrange(desc(log_odds)) %>% head(20)
top_negative <- word_log_odds %>% filter(sentiment_label == "negative") %>% arrange(log_odds) %>% head(20)

print(top_positive)
print(top_negative)
```
```{r}
# 8. Seleziona le top 10 parole per ciascuna classe
top_positive <- word_log_odds %>%
  filter(sentiment_label == "positive") %>%
  top_n(10, log_odds) %>%
  arrange(log_odds)

top_negative <- word_log_odds %>%
  filter(sentiment_label == "negative") %>%
  top_n(10, -log_odds) %>%
  arrange(log_odds)

# 9. Funzione per generare il grafico a barre con colori pastello
plot_top_words <- function(df, title) {
  df <- df %>%
    mutate(word = fct_reorder(word, log_odds))
  ggplot(df, aes(x = word, y = log_odds, fill = sentiment_label)) +
    geom_col(show.legend = FALSE) +
    coord_flip() +
    scale_fill_manual(values = c(
      positive = "#AEDFF7",  # pastello arancione
      negative = "#B2E8B2",  # pastello verde
      neutral = "#CCCCCC"    # grigio per neutri, se presenti
    )) +
    labs(title = title,
         x = "Parola",
         y = "Log Odds Ratio") +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      axis.text = element_text(size = 12),
      axis.title = element_text(size = 12)
    )
}

# 10. Genera i grafici
gg_positive <- plot_top_words(top_positive, "Top 10 Parole Positive (log-odds)")
gg_negative <- plot_top_words(top_negative, "Top 10 Parole Negative (log-odds)")

# 11. Mostra i grafici
print(gg_positive)
print(gg_negative)

```


RETE DEI COMMENTI CON SENTIMENT
```{r}
# 1. Prepara i nodi con polarità
nodes <- sentiment_comments %>%
  mutate(polarity_class = case_when(
    polarity > 0 ~ "positive",
    polarity < 0 ~ "negative",
    TRUE ~ "neutral"
  )) %>%
  rename(name = comment_id)  # fondamentale per tbl_graph

# 2. Prepara gli archi (da padre a figlio)
edges <- data1 %>%
  select(from = parent_comment_id, to = comment_id) %>%
  filter(!is.na(from)) %>%
  filter(from %in% nodes$name & to %in% nodes$name)

# 3. Crea il grafo
graph <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)

# 4. Visualizzazione con ggraph
ggraph(graph, layout = "tree") +
  geom_edge_link(alpha = 0.3, arrow = arrow(length = unit(2, 'mm')), end_cap = circle(3, 'mm')) +
  geom_node_point(aes(color = polarity_class), size = 3) +
  scale_color_manual(values = c(
    "positive" = "#66c2a5",
    "negative" = "#fc8d62",
    "neutral" = "#8da0cb"
  )) +
  theme_void() +
  labs(title = "Rete dei Commenti con Polarità del Sentimento")
```





