---
title: "Sentiment_analysis"
output: html_document
date: "2025-05-31"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(syuzhet)
library(dplyr)
library(readr)
library(tidytext)
library(tidyverse)
library(textclean)
library(topicmodels)
library(devtools)
library(tokenizers)
library(stringr)
library(tibble)
library(ggplot2)
library(keras)
library(yardstick)
library(text2vec)
library(cluster)
library(factoextra)


#install.packages(c("tm", "BMS", "quadprog", "rJava", "parallel", "data.table", "entropy"))
#library(rJava)
#.jinit()
#remotes::install_github("blogsvoices/iSAX")
```


```{r cars}
data1<-read_csv("/Users/melaniauccello/Desktop/Network science e text mining/Exame_TextMining/nutrition_comments_cleaned.csv")
View(data1)

data2<-read_csv("/Users/melaniauccello/Desktop/Network science e text mining/Exame_TextMining/nutrition_threads_cleaned.csv")
View(data2)
```
### Analisi dei set di dati come unico documento per capire il sentimento predominante
```{r}
# Unisci tutti i testi della colonna 'Cleaned_Comment' in un singolo testo (per data1)
text1 <- paste(data1$Cleaned_Comment, collapse = " ")

# Unisci tutti i testi della colonna 'Cleaned_Text' in un singolo testo (per data2)
text2 <- paste(data2$Cleaned_Text, collapse = " ")

```

```{r}
# Analisi del sentiment per il testo del data1
sentiment1 <- get_nrc_sentiment(text1)

# Analisi del sentiment per il testo del data2
sentiment2 <- get_nrc_sentiment(text2)

# Visualizza i risultati
print(colSums(sentiment1))
print(colSums(sentiment2))

```
```{r}
sentiment_pred1<-which.max(colSums(sentiment1))  # Sentimento dominante data1
sentiment_pred2<-which.max(colSums(sentiment2))# Sentimento dominante data2

print(sentiment_pred1)
print(sentiment_pred1)
```


```{r}
nrc <- get_sentiments("nrc")
# Prepara comments
comments <- data1 %>%
  select(text = Cleaned_Comment) %>%
  mutate(source = "comments")

# Prepara threads
threads <- data2 %>%
  select(text = Cleaned_Text) %>%
  mutate(source = "threads")

# Carica NRC (solo emozioni)
nrc_emotions <- get_sentiments("nrc") %>%
  filter(!sentiment %in% c("positive", "negative"))

# Tokenizzazione + conteggio per comments
emotion_comments <- comments %>%
  unnest_tokens(word, text) %>%
  inner_join(nrc_emotions, by = "word") %>%
  count(sentiment, sort = TRUE) %>%
  mutate(percent = n / sum(n) * 100,
         source = "comments")

# Tokenizzazione + conteggio per threads
emotion_threads <- threads %>%
  unnest_tokens(word, text) %>%
  inner_join(nrc_emotions, by = "word") %>%
  count(sentiment, sort = TRUE) %>%
  mutate(percent = n / sum(n) * 100,
         source = "threads")


ggplot(emotion_comments, aes(x = reorder(sentiment, -percent), y = percent)) +
  geom_bar(stat = "identity", fill = "#66c2a5") +
  labs(title = "Distribuzione Emozioni nei Commenti", x = "Emozione", y = "Frequenza (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


ggplot(emotion_threads, aes(x = reorder(sentiment, -percent), y = percent)) +
  geom_bar(stat = "identity", fill = "#fc8d62") +
  labs(title = "Distribuzione Emozioni nei Thread", x = "Emozione", y = "Frequenza (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
# Unione dei due dataset
emotion_comparison <- bind_rows(emotion_comments, emotion_threads)
ggplot(emotion_comparison, aes(x = sentiment, y = percent, fill = source)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Confronto delle Emozioni tra Commenti e Thread",
    x = "Emozione",
    y = "Frequenza (%)",
    fill = "Fonte"
  ) +
  scale_fill_manual(values = c("comments" = "#66c2a5", "threads" = "#fc8d62")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### Valutazione del sentimento di ciascuna frase nei due set di dati (separatamente) al fine di individuare le opinioni contrastanti

```{r}
# Calcola il sentiment per ciascun commento
sentiment_data1 <- get_nrc_sentiment(data1$Cleaned_Comment)

# Combina i risultati con i dati originali
data1_sentiment <- bind_cols(data1, sentiment_data1)

# Visualizza le prime righe
head(data1_sentiment)

```

```{r}
# Calcola il sentiment per ciascun commento
sentiment_data2 <- get_nrc_sentiment(data2$Cleaned_Text)

# Combina i risultati con i dati originali
data2_sentiment <- bind_cols(data2, sentiment_data2)

# Visualizza le prime righe
head(data2_sentiment)

```

```{r}
# Funzione per determinare contrasto
check_contrast <- function(df) {
  df %>%
    mutate(
      positive = positive,
      negative = negative,
      contrast = ifelse(positive > 0 & negative > 0, TRUE, FALSE)
    )
}

# Applica la funzione
data1_sentiment <- check_contrast(data1_sentiment)
data2_sentiment <- check_contrast(data2_sentiment)

# Filtra solo i commenti contrastanti
contrasting_comments1 <- filter(data1_sentiment, contrast == TRUE)
contrasting_comments2 <- filter(data2_sentiment, contrast == TRUE)

# Visualizza
#contrasting_comments1$Cleaned_Comment
#contrasting_comments2$Cleaned_Text

head(contrasting_comments1$Cleaned_Comment, 10)
head(contrasting_comments2$Cleaned_Text, 10).
```

### ABSA

In sentiment analysis, polarità indica la direzione emotiva espressa in un testo:
Positive, Neutral, Negative.
Abbiamo definito un dizionario manuale con parole chiave.
Ogni commento/testo è stato diviso in frasi per analizzare in modo più preciso le emozioni per ciascun aspetto.
Abbiamo selezionato solo le frasi contenenti almeno uno degli aspetti del dizionario.
Abbiamo usato syuzhet::get_sentiment() per assegnare un punteggio numerico di sentiment a ciascuna frase. Poi lo abbiamo trasformato in polarità (positive, negative, neutral).

```{r}
# Dizionario manuale di aspetti rilevanti per nutrizione
aspect_terms <- c("appointment", "goal", "rapport", "session", "diet", "supplement", "follow-up", "plan", "history")

# Tokenizza i commenti in frasi
data1_sentences <- data1 %>%
  mutate(sentences = tokenize_sentences(Cleaned_Comment)) %>%
  unnest(sentences) %>%
  rename(sentence = sentences)

# Filtra solo le frasi che contengono almeno un aspetto
aspect_pattern <- str_c("\\b(", str_c(aspect_terms, collapse = "|"), ")\\b")
data1_aspects <- data1_sentences %>%
  filter(str_detect(sentence, regex(aspect_pattern, ignore_case = TRUE)))

# Calcola il sentiment della frase
data1_aspects <- data1_aspects %>%
  mutate(sentiment_score = get_sentiment(sentence, method = "syuzhet"),
         polarity = case_when(
           sentiment_score > 0 ~ "positive",
           sentiment_score < 0 ~ "negative",
           TRUE ~ "neutral"
         ))

View(data1_aspects)
```

```{r}
data1_aspects %>%
  count(polarity, sort = TRUE)

data1_aspects %>%
  group_by(polarity) %>%
  summarise(avg_sentiment = mean(sentiment_score))

```

```{r}
# Dizionario manuale di aspetti rilevanti per nutrizione
# Includi aspetti multi-parola
aspect_terms <- c(
  "appointment", "goal", "rapport", "session", "diet", "supplement",
  "follow-up", "plan", "history", "retention", "counselling", "assessment",
  "meal plan",          # Esempio di aspetto multi-parola
  "eating habits",      # Esempio di aspetto multi-parola
  "nutrition plan",     # Esempio di aspetto multi-parola
  "healthy eating",     # Esempio di aspetto multi-parola
  "weight loss",        # Esempio di aspetto multi-parola
  "food choices",       # Esempio di aspetto multi-parola
  "dietary changes"     # Esempio di aspetto multi-parola
)

# Per creare il pattern, assicurati che le frasi più lunghe vengano controllate per prime
# Questo evita che "plan" venga trovato prima di "nutrition plan"
aspect_terms_ordered <- aspect_terms[order(-nchar(aspect_terms))]

# Crea il pattern regex per la ricerca degli aspetti, ignorando le maiuscole/minuscole.
# Usiamo str_c(..., collapse = "|") per unire i termini con un OR.
# L'uso di "\\b" (boundary) è più adatto per singole parole.
# Per frasi, potremmo voler essere più flessibili o usare una logica diversa.
# Un approccio comune è usare la funzione 'str_detect' con 'regex' e 'ignore_case'.
# Per includere multi-parole, potremmo semplicemente elencarle, e l'ordine aiuta.
aspect_pattern <- str_c("(", str_c(aspect_terms_ordered, collapse = "|"), ")")

# Modifica le tue sezioni data1_aspects e data2_aspects come segue:

# Filtra solo le frasi che contengono almeno un aspetto
data1_aspects <- data1_sentences %>%
  filter(str_detect(sentence, regex(aspect_pattern, ignore_case = TRUE)))

# Calcola il sentiment della frase
data1_aspects <- data1_aspects %>%
  mutate(sentiment_score = get_sentiment(sentence, method = "syuzhet"),
         polarity = case_when(
           sentiment_score > 0 ~ "positive",
           sentiment_score < 0 ~ "negative",
           TRUE ~ "neutral"
         ))

View(data1_aspects)

# Ripeti lo stesso per data2_aspects:
data2_sentences <- data2 %>%
  mutate(sentences = tokenize_sentences(Cleaned_Text)) %>%
  unnest(sentences) %>%
  rename(sentence = sentences)

data2_aspects <- data2_sentences %>%
  filter(str_detect(sentence, regex(aspect_pattern, ignore_case = TRUE)))

data2_aspects <- data2_aspects %>%
  mutate(sentiment_score = get_sentiment(sentence, method = "syuzhet"),
         polarity = case_when(
           sentiment_score > 0 ~ "positive",
           sentiment_score < 0 ~ "negative",
           TRUE ~ "neutral"
         ))
```



```{r}
data2_aspects %>%
  count(polarity, sort = TRUE)

data2_aspects %>%
  group_by(polarity) %>%
  summarise(avg_sentiment = mean(sentiment_score))

```
Differenze di polarità tra commenti e threads

```{r}
# Aggiungiamo etichette
data1_aspects <- data1_aspects %>% mutate(source = "comments")
data2_aspects <- data2_aspects %>% mutate(source = "threads")

# Unione
all_aspects <- bind_rows(data1_aspects, data2_aspects)

ggplot(all_aspects, aes(x = polarity, fill = source)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Confronto Polarità tra Commenti e Thread",
    x = "Polarità del Sentimento",
    y = "Numero di Frasi"
  ) +
  scale_fill_manual(values = c("comments" = "#66c2a5", "threads" = "#fc8d62")) +
  theme_minimal()

```
## Comparative sentiment analysis

Ricostruiamo la gerarchia commenti tramite comment_id
Calcoliamo la polarità (positivo/negativo) per ogni commento
Mettiamo in relazione i commenti con i loro “padri” (commenti cui rispondono)
Valutiamo se sono in accordo o disaccordo emotivo

```{r}
# Funzione per ottenere il comment_id padre
get_parent_id <- function(cid) {
  if (!str_detect(cid, "_")) {
    return(NA) # commento root, no padre
  } else {
    parts <- str_split(cid, "_")[[1]]
    parent_id <- paste(parts[-length(parts)], collapse = "_")
    return(parent_id)
  }
}

data1 <- data1 %>%
  mutate(parent_comment_id = sapply(comment_id, get_parent_id))
```

```{r}
nrc <- get_sentiments("nrc")

# Sentiment positivo/negativo (esempio polarità)
sentiment_comments <- data1 %>%
  select(comment_id, Cleaned_Comment) %>%
  unnest_tokens(word, Cleaned_Comment) %>%
  inner_join(nrc %>% filter(sentiment %in% c("positive", "negative")), by = "word") %>%
  count(comment_id, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(polarity = positive - negative)

```

```{r}
# Unisci polarità commento e padre
paired_sentiments <- data1 %>%
  select(comment_id, parent_comment_id) %>%
  inner_join(sentiment_comments %>% select(comment_id, polarity), by = "comment_id") %>%
  left_join(sentiment_comments %>% select(comment_id, polarity), by = c("parent_comment_id" = "comment_id"), suffix = c("_child", "_parent")) %>%
  filter(!is.na(polarity_parent))  # escludi root senza padre

```


```{r}
paired_sentiments <- paired_sentiments %>%
  mutate(agreement = case_when(
    polarity_child * polarity_parent > 0 ~ "accordo",    # stesse polarità (positivo/positivo o negativo/negativo)
    polarity_child * polarity_parent < 0 ~ "disaccordo", # polarità opposte
    TRUE ~ "neutro"                                      # zero o indeterminato
  ))

table(paired_sentiments$agreement)

```

```{r}
paired_sentiments %>%
  count(agreement) %>%
  mutate(percent = n / sum(n) * 100) %>%
  ggplot(aes(x = agreement, y = percent, fill = agreement)) +
  geom_bar(stat = "identity") +
  labs(title = "Accordo/Disaccordo nei commenti figlio-padre",
       x = "Tipo di relazione sentimentale",
       y = "Percentuale (%)") +
  theme_minimal()

```
### Sentiment Lexicon Acquisition

Il lexicon è il prodotto finale: un dizionario con parole e punteggi sentimentali.
La lexicon acquisition è il processo per generare quel dizionario, in modo automatico, partendo da dati con annotazioni (ad esempio commenti con score).

Lo script con log-odds ratio usa i commenti etichettati (positivi vs negativi), in seguito calcola quali parole sono più rappresentative di ciascun sentimento
genera così un lexicon personalizzato basato sul tuo dominio (commenti sulla nutrizione)


Si parte da un corpus testuale (es. i tuoi commenti/thread)
Si identifica il sentiment delle parole o espressioni tramite metodi automatici o semi-automatici
Si crea o aggiorna un dizionario parola → polarità/emozione

```{r}
# 2. Definisci la classe di sentiment sulla base del punteggio
data1 <- data1 %>%
  mutate(sentiment_class = case_when(
    score >= 5 ~ "positive",
    score <= 3 ~ "negative",
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(sentiment_class))  # escludi neutri

# 3. Tokenizza i testi
tokens <- data1 %>%
  unnest_tokens(word, Cleaned_Comment) %>%
  filter(!str_detect(word, "\\d")) %>%  # opzionale: rimuovi token numerici
  filter(str_length(word) > 1)          # opzionale: rimuovi parole di 1 carattere

# 4. Conta le occorrenze di ogni parola per classe sentiment
word_counts <- tokens %>%
  count(sentiment_class, word) %>%
  group_by(word) %>%
  filter(sum(n) > 10) %>%  # usa solo parole con frequenza totale > 10
  ungroup()

# 5. Calcola le frequenze totali per classe
total_counts <- word_counts %>%
  group_by(sentiment_class) %>%
  summarise(total = sum(n))

# Conta le occorrenze di ogni parola per classe sentiment
word_counts <- tokens %>%
  count(sentiment_class, word) %>%
  group_by(word) %>%
  filter(sum(n) > 10) %>%  # frequenza minima per parola
  ungroup()

# Calcola totali globali per classe
total_positive <- sum(word_counts$n[word_counts$sentiment_class == "positive"])
total_negative <- sum(word_counts$n[word_counts$sentiment_class == "negative"])

# Riorganizza i dati in wide per parole con conti per classe
word_log_odds <- word_counts %>%
  pivot_wider(names_from = sentiment_class, values_from = n, values_fill = list(n = 0)) %>%
  mutate(
    log_odds = log( (positive + 1) / (total_positive + 1) ) - log( (negative + 1) / (total_negative + 1) )
  ) %>%
  arrange(desc(log_odds))

# Visualizza i risultati
head(word_log_odds)

```
log_odds = misura di associazione: più è alta, più la parola è tipica dei positivi, più è bassa (negativa), più la parola è tipica dei negativi.

```{r}
word_log_odds <- word_log_odds %>%
  mutate(sentiment_label = case_when(
    log_odds > 1 ~ "positive",
    log_odds < -1 ~ "negative",
    TRUE ~ "neutral"
  ))

top_positive <- word_log_odds %>% filter(sentiment_label == "positive") %>% arrange(desc(log_odds)) %>% head(20)
top_negative <- word_log_odds %>% filter(sentiment_label == "negative") %>% arrange(log_odds) %>% head(20)

print(top_positive)
print(top_negative)
```

### PREVISIONE SUPERVISIONATA


### PREVISIONE NON SUPERVISIONATA

