---
title: "Topic detection"
author: "Mariateresa Russo"
date: "2025-05-31"
output: html_document
---
```{r}
library(knitr) 
library(kableExtra) 
library(DT)
library(tm)
library(topicmodels)
library(reshape2)
library(ggplot2)
library(wordcloud)
library(pals)
library(SnowballC)
library(lda)
library(flextable)

df_new_comments = read.csv("nutrition_comments_cleaned.csv")
df_new_threads = read.csv("nutrition_threads_cleaned.csv")

combined_df <- data.frame(Cleaned_Text = c(df_new_threads$Cleaned_text, df_new_comments$Cleaned_Comment))

```

Lettura del Corpus
Term Document Matrix
```{r}
# Trova tutte le colonne presenti in entrambi i dataframe
all_cols <- union(names(final_df), names(final_df2))

# Aggiungi le colonne mancanti in final_df, con valore 0
for (col in setdiff(all_cols, names(final_df))) {
  final_df[[col]] <- 0
}
# Aggiungi le colonne mancanti in final_df2, con valore 0
for (col in setdiff(all_cols, names(final_df2))) {
  final_df2[[col]] <- 0
}
# Riordina le colonne in entrambi i dataframe per avere lo stesso ordine
final_df <- final_df[ , all_cols]
final_df2 <- final_df2[ , all_cols]
# Concatena con rbind
final_df_combined <- rbind(final_df, final_df2)

final_df
final_df2
final_df_combined

DTM <- final_df_combined
```

rimozione documenti vuoti
```{r}
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
```

tuning per trovare il numero ottimale di topics----DA MIGLIORARE  O RIMUOVERE
```{r}
library(topicmodels)

seq_k <- 2:7
log_liks <- numeric(length(seq_k))

for (i in seq_along(seq_k)) {
  lda_model <- LDA(DTM, k = seq_k[i], method = "Gibbs", control = list(seed = 77))
  log_liks[i] <- logLik(lda_model)
}

plot(seq_k, log_liks, type = "b", xlab = "Numero di topics", ylab = "Log-likelihood")
```

```{r}
set.seed(9161)
# compute the LDA model, inference via 1000 iterations of Gibbs sampling
topicModel <- LDA(DTM, 5, method="Gibbs", control=list(iter = 500, verbose = 25))
topicModel
```




```{r}

# Preprocessing: tokenizzazione + rimozione stopwords
tidy_titles <- df_new_threads %>%
  mutate(doc_id = row_number()) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words)

# Creazione della Document-Term Matrix
dtm <- tidy_titles %>%
  count(doc_id, word) %>%
  cast_dtm(doc_id, word, n)

# Applica LDA (scegli numero topic, es. 4)
lda_model <- LDA(dtm, k = 4, control = list(seed = 123))

# Vedi parole chiave per ogni topic
topics <- tidy(lda_model, matrix = "beta")  # beta = probabilità parola|topic

top_terms <- topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualizzazione semplice
top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_x_reordered() +
  coord_flip() +
  labs(title = "Top terms per topic", x = "", y = "Beta (importance)")

```
Ecco i 4 topic rilevati:

Pratica clinica e gestione del peso
(rds, clinical, experience, weight, loss)

Nutrizione generale e consigli per i pazienti
(nutrition, advice, pay, dietician, protein)

Carriera professionale nel campo della dietetica
(dietitian, career, dietitians, job, dietetics)

Libera professione e regolamentazione
(practice, nutrition, private, cdr, rds)












COMMENTI
```{r}
# Preprocessing: tokenizzazione + rimozione stopwords
tidy_titles <- df_new_comments %>%
  mutate(doc_id = row_number()) %>%
  unnest_tokens(word, Cleaned_Comment) %>%
  anti_join(stop_words)

# Creazione della Document-Term Matrix
dtm <- tidy_titles %>%
  count(doc_id, word) %>%
  cast_dtm(doc_id, word, n)

# Applica LDA (scegli numero topic, es. 4)
lda_model <- LDA(dtm, k = 4, control = list(seed = 123))

# Vedi parole chiave per ogni topic
topics <- tidy(lda_model, matrix = "beta")  # beta = probabilità parola|topic

top_terms <- topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualizzazione semplice
top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_x_reordered() +
  coord_flip() +
  labs(title = "Top terms per topic", x = "", y = "Beta (importance)")
```

