---
title: "Topic detection"
author: "Mariateresa Russo"
date: "2025-05-31"
output: html_document
---
```{r}
library(knitr) 
library(kableExtra) 
library(DT)
library(tm)
library(topicmodels)
library(reshape2)
library(ggplot2)
library(wordcloud)
library(pals)
library(SnowballC)
library(lda)
library(flextable)
```

Lettura del Corpus
Term Document Matrix
```{r}
# Trova tutte le colonne presenti in entrambi i dataframe
all_cols <- union(names(final_df_threads), names(final_df_comments))

# Aggiungi le colonne mancanti in final_df, con valore 0
for (col in setdiff(all_cols, names(final_df_threads))) {
  final_df_threads[[col]] <- 0
}
# Aggiungi le colonne mancanti in final_df2, con valore 0
for (col in setdiff(all_cols, names(final_df_comments))) {
  final_df_comments[[col]] <- 0
}
# Riordina le colonne in entrambi i dataframe per avere lo stesso ordine
final_df <- final_df_threads[ , all_cols]
final_df2 <- final_df_comments[ , all_cols]
# Concatena con rbind
final_df_combined <- rbind(final_df_threads, final_df_comments)

final_df_threads
final_df_comments
final_df_combined

DTM <- final_df_combined
```

rimozione documenti vuoti
```{r}
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
DTM <- as.matrix(DTM)
```


LDA prediction
```{r}
set.seed(9161)
# compute the LDA model, inference via 1000 iterations of Gibbs sampling
topicModel <- LDA(DTM, 3, method="Gibbs", control=list(iter = 500, verbose = 25))
topicModel
```

```{r}
tmResult <- posterior(topicModel)
attributes(tmResult)

# for every document we have a probability distribution of its contained topics
theta <- tmResult$topics 
dim(theta)

terms(topicModel, 20)

tmResult$topics %>% head(20)
```

parole chiave per topic
beta ti dice, per ogni topic, quanto è probabile ciascuna parola del vocabolario
```{r}
topics <- tidy(topicModel, matrix = "beta")  # beta = probabilità parola|topic

top_terms <- topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 20) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualizzazione semplice
top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_x_reordered() +
  coord_flip() +
  labs(title = "Top terms per topic", x = "", y = "Beta (importance)")

```
Ecco i 3 topic rilevati:

Rosso --> Alimentazione, salute e pazienti

Verde --> Parole molto colloquiali e soggettive. Opinioni personali, atteggiamenti o esperienze

Blu --> Carriera professionale nel campo della dietetica











